"""
Unit tests for Bulyan paper-compliance per El Mhamdi et al. 2018.

Tests verify:
1. Coordinate-wise trimmed mean correctness
2. Bulyan selection count (θ = n - 2f)
3. Bulyan trimming parameter (β = 2f)
4. Validation of n >= 4f + 3 requirement
5. Byzantine resilience properties
6. Property-based tests for trimmed mean invariants
"""

from __future__ import annotations

import numpy as np
import pytest
from hypothesis import given, strategies as st

from robust_aggregation import (
    AggregationMethod,
    _coordinate_wise_trimmed_mean,
    _bulyan_aggregate,
    aggregate_weights,
)


def _make_simple_client_updates(n_clients: int, n_layers: int = 2, shape=(3,)):
    """Create simple client updates with known values for testing."""
    rng = np.random.default_rng(42)
    clients = []
    for i in range(n_clients):
        layers = []
        for _ in range(n_layers):
            layers.append(rng.normal(loc=0.0, scale=1.0, size=shape))
        clients.append(layers)
    return clients


# ============================================================================
# Tests for _coordinate_wise_trimmed_mean
# ============================================================================


def test_trimmed_mean_with_zero_beta_returns_simple_mean():
    """Trimmed mean with beta=0 should equal simple mean (no trimming)."""
    values = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])
    expected_mean = np.mean(values, axis=0)
    result = _coordinate_wise_trimmed_mean(values, beta=0)
    np.testing.assert_array_almost_equal(result, expected_mean)


def test_trimmed_mean_removes_extremes_symmetrically():
    """Trimmed mean should remove beta/2 smallest and largest values per coordinate."""
    # Construct array where coordinate 0 has clear extremes
    # Candidates: [1, 5, 9], should trim 1 and 9, leaving 5
    values = np.array([[1.0, 10.0], [5.0, 20.0], [9.0, 30.0]])
    beta = 2  # Trim 1 from each end
    result = _coordinate_wise_trimmed_mean(values, beta)
    # After trimming [1, 9], mean of [5] = 5.0
    # After trimming [10, 30], mean of [20] = 20.0
    expected = np.array([5.0, 20.0])
    np.testing.assert_array_almost_equal(result, expected)


def test_trimmed_mean_with_five_candidates_beta_two():
    """Trimmed mean with 5 candidates, beta=2 should trim 1 from each end."""
    # Values designed so trimming is obvious
    values = np.array(
        [
            [0.0],  # Will be trimmed (smallest)
            [2.0],
            [4.0],
            [6.0],
            [100.0],  # Will be trimmed (largest)
        ]
    )
    beta = 2
    result = _coordinate_wise_trimmed_mean(values, beta)
    # After trimming [0.0, 100.0], mean of [2.0, 4.0, 6.0] = 4.0
    expected = np.array([4.0])
    np.testing.assert_array_almost_equal(result, expected)


def test_trimmed_mean_rejects_negative_beta():
    """Trimmed mean should raise ValueError for negative beta."""
    values = np.array([[1.0], [2.0], [3.0]])
    with pytest.raises(ValueError, match="beta must be non-negative"):
        _coordinate_wise_trimmed_mean(values, beta=-1)


def test_trimmed_mean_rejects_odd_beta():
    """Trimmed mean should raise ValueError for odd beta (asymmetric trimming)."""
    values = np.array([[1.0], [2.0], [3.0]])
    with pytest.raises(ValueError, match="beta must be even"):
        _coordinate_wise_trimmed_mean(values, beta=1)


def test_trimmed_mean_rejects_beta_equal_to_candidate_count():
    """Trimmed mean should raise ValueError when beta >= n_candidates."""
    values = np.array([[1.0], [2.0], [3.0], [4.0]])
    n_candidates = 4
    with pytest.raises(ValueError, match=f"beta \\({n_candidates}\\) must be less than number of candidates"):
        _coordinate_wise_trimmed_mean(values, beta=n_candidates)


def test_trimmed_mean_rejects_beta_exceeding_candidate_count():
    """Trimmed mean should raise ValueError when beta > n_candidates."""
    values = np.array([[1.0], [2.0], [3.0]])
    with pytest.raises(ValueError, match="beta \\(4\\) must be less than number of candidates \\(3\\)"):
        _coordinate_wise_trimmed_mean(values, beta=4)


def test_trimmed_mean_handles_multidimensional_arrays():
    """Trimmed mean should work correctly with multi-dimensional layer arrays."""
    # Shape: (4 candidates, 2x2 layer)
    values = np.array(
        [
            [[1.0, 2.0], [3.0, 4.0]],  # Candidate 0
            [[5.0, 6.0], [7.0, 8.0]],  # Candidate 1
            [[9.0, 10.0], [11.0, 12.0]],  # Candidate 2
            [[100.0, 200.0], [300.0, 400.0]],  # Candidate 3 (outlier)
        ]
    )
    beta = 2  # Trim 1 from each end
    result = _coordinate_wise_trimmed_mean(values, beta)
    # After sorting each coordinate and trimming min/max:
    # Coordinate [0,0]: [1, 5, 9, 100] -> trim [1, 100] -> mean([5, 9]) = 7.0
    # Coordinate [0,1]: [2, 6, 10, 200] -> trim [2, 200] -> mean([6, 10]) = 8.0
    # Coordinate [1,0]: [3, 7, 11, 300] -> trim [3, 300] -> mean([7, 11]) = 9.0
    # Coordinate [1,1]: [4, 8, 12, 400] -> trim [4, 400] -> mean([8, 12]) = 10.0
    expected = np.array([[7.0, 8.0], [9.0, 10.0]])
    np.testing.assert_array_almost_equal(result, expected)


def test_trimmed_mean_rejects_non_array_input():
    """Trimmed mean should raise TypeError for non-numpy array input."""
    values_list = [[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]
    with pytest.raises(TypeError, match="stacked must be numpy.ndarray, got list"):
        _coordinate_wise_trimmed_mean(values_list, beta=0)


def test_trimmed_mean_rejects_zero_dimensional_array():
    """Trimmed mean should raise ValueError for 0-d array."""
    values = np.array(5.0)  # 0-d array
    with pytest.raises(ValueError, match="stacked must have at least 1 dimension"):
        _coordinate_wise_trimmed_mean(values, beta=0)


# ============================================================================
# Tests for _bulyan_aggregate validation
# ============================================================================


def test_bulyan_requires_minimum_client_count_for_f_equals_one():
    """Bulyan should reject n < 4f + 3 (with f=1, need n >= 7)."""
    n_clients = 6
    f = 1
    min_required = 4 * f + 3  # 7
    clients = _make_simple_client_updates(n_clients)

    with pytest.raises(
        ValueError,
        match=f"Bulyan requires n >= 4f \\+ 3 for Byzantine resilience.*Got n={n_clients}, f={f}, but need n >= {min_required}",
    ):
        _bulyan_aggregate(clients, f=f)


def test_bulyan_requires_minimum_client_count_for_f_equals_two():
    """Bulyan should reject n < 4f + 3 (with f=2, need n >= 11)."""
    n_clients = 10
    f = 2
    min_required = 4 * f + 3  # 11
    clients = _make_simple_client_updates(n_clients)

    with pytest.raises(
        ValueError,
        match=f"Bulyan requires n >= 4f \\+ 3 for Byzantine resilience.*Got n={n_clients}, f={f}, but need n >= {min_required}",
    ):
        _bulyan_aggregate(clients, f=f)


def test_bulyan_accepts_exactly_minimum_client_count():
    """Bulyan should accept exactly n = 4f + 3 clients."""
    f = 1
    n_clients = 4 * f + 3  # 7
    clients = _make_simple_client_updates(n_clients)

    # Should not raise
    result = _bulyan_aggregate(clients, f=f)
    assert len(result) == len(clients[0])


def test_bulyan_accepts_more_than_minimum_client_count():
    """Bulyan should accept n > 4f + 3 clients."""
    f = 1
    n_clients = 10  # > 4*1 + 3 = 7
    clients = _make_simple_client_updates(n_clients)

    # Should not raise
    result = _bulyan_aggregate(clients, f=f)
    assert len(result) == len(clients[0])


# ============================================================================
# Tests for Bulyan paper-compliance properties
# ============================================================================


def test_bulyan_selection_count_equals_n_minus_2f():
    """Bulyan should select exactly θ = n - 2f candidates (not n - f - 2)."""
    n_clients = 11  # For f=2, need 4*2+3=11
    f = 2
    # Expected: θ = n - 2f = 11 - 4 = 7 candidates selected

    clients = _make_simple_client_updates(n_clients)

    # We can't directly observe selection count without modifying code,
    # but we can verify the algorithm doesn't crash and produces valid output
    result = _bulyan_aggregate(clients, f=f)
    assert len(result) == len(clients[0])

    # Additional sanity check: result should be finite
    for layer in result:
        assert np.isfinite(layer).all()


def test_bulyan_with_outliers_is_more_robust_than_mean():
    """Bulyan should be robust to Byzantine outliers unlike simple mean."""
    n_clients = 11  # For f=2, need 4*2+3=11
    f = 2
    clients = _make_simple_client_updates(n_clients)

    # Inject 2 Byzantine outliers at LAST positions (unlikely to be Krum-selected)
    # Krum selects clients with smallest distances to neighbors, so extreme
    # outliers at the end are least likely to be chosen
    outlier_value_1 = 500.0
    outlier_value_2 = 800.0
    byzantine_idx_1 = n_clients - 1
    byzantine_idx_2 = n_clients - 2

    for layer_idx in range(len(clients[0])):
        clients[byzantine_idx_1][layer_idx] = np.full_like(clients[byzantine_idx_1][layer_idx], outlier_value_1)
        clients[byzantine_idx_2][layer_idx] = np.full_like(clients[byzantine_idx_2][layer_idx], outlier_value_2)

    # Compute Bulyan aggregate
    bulyan_result = _bulyan_aggregate(clients, f=f)

    # Compute simple mean for comparison
    mean_result = []
    for layer_idx in range(len(clients[0])):
        stacked = np.stack([c[layer_idx] for c in clients], axis=0)
        mean_result.append(np.mean(stacked, axis=0))

    # Bulyan should produce values much closer to honest clients than mean
    bulyan_magnitude = np.mean([np.abs(layer).mean() for layer in bulyan_result])
    mean_magnitude = np.mean([np.abs(layer).mean() for layer in mean_result])

    # Bulyan magnitude should be < 50, mean magnitude should be much larger (>100)
    assert bulyan_magnitude < 50.0
    assert mean_magnitude > 100.0  # Mean is heavily influenced by outliers


def test_bulyan_aggregate_via_public_api():
    """Test Bulyan aggregation through public aggregate_weights API."""
    n_clients = 11  # For f=2, need 4*2+3=11
    f = 2
    clients = _make_simple_client_updates(n_clients)

    # Inject outliers
    for layer_idx in range(len(clients[0])):
        clients[0][layer_idx] = clients[0][layer_idx] + 100.0
        clients[1][layer_idx] = clients[1][layer_idx] - 100.0

    result = aggregate_weights(clients, AggregationMethod.BULYAN, byzantine_f=f)

    # Should produce finite values
    assert len(result) == len(clients[0])
    for layer in result:
        assert np.isfinite(layer).all()

    # Should not be dominated by outliers
    magnitude = np.mean([np.abs(layer).mean() for layer in result])
    assert magnitude < 50.0


def test_bulyan_trimming_parameter_equals_2f():
    """Bulyan should use β = 2f for coordinate-wise trimming."""
    # This is implicitly tested by the robustness test above,
    # but we verify the algorithm produces reasonable output
    n_clients = 11
    f = 2
    clients = _make_simple_client_updates(n_clients)

    result = _bulyan_aggregate(clients, f=f)

    # Result should match expected layer structure
    assert len(result) == len(clients[0])
    for i, layer in enumerate(result):
        assert layer.shape == clients[0][i].shape


def test_bulyan_empty_input_returns_empty():
    """Bulyan should return empty list for empty input."""
    result = _bulyan_aggregate([], f=1)
    assert result == []


def test_bulyan_preserves_layer_shapes():
    """Bulyan aggregation should preserve layer shapes from input clients."""
    n_clients = 11
    f = 2
    layer_shapes = [(5,), (3, 3), (10, 2)]
    n_layers = len(layer_shapes)

    rng = np.random.default_rng(123)
    clients = []
    for _ in range(n_clients):
        layers = [rng.normal(0, 1, size=shape) for shape in layer_shapes]
        clients.append(layers)

    result = _bulyan_aggregate(clients, f=f)

    assert len(result) == n_layers
    for layer_result, expected_shape in zip(result, layer_shapes):
        assert layer_result.shape == expected_shape


# ============================================================================
# Property-based tests for trimmed mean invariants
# ============================================================================


@given(
    n_candidates=st.integers(min_value=3, max_value=20),
    value=st.floats(min_value=-100.0, max_value=100.0, allow_nan=False, allow_infinity=False),
)
def test_trimmed_mean_idempotence_property(n_candidates, value):
    """Property: trimmed_mean([x]*n, beta=0) == x (idempotence)."""
    stacked = np.full((n_candidates, 1), value)
    result = _coordinate_wise_trimmed_mean(stacked, beta=0)
    np.testing.assert_almost_equal(result[0], value, decimal=5)


@given(
    n_candidates=st.integers(min_value=5, max_value=15),
    values=st.lists(st.floats(min_value=-50.0, max_value=50.0, allow_nan=False, allow_infinity=False), min_size=5, max_size=15),
)
def test_trimmed_mean_bounds_property(n_candidates, values):
    """Property: trimmed mean should be between min and max of input values."""
    # Ensure we have exactly n_candidates values
    if len(values) > n_candidates:
        values = values[:n_candidates]
    elif len(values) < n_candidates:
        return  # Skip if we don't have enough values

    stacked = np.array(values).reshape(-1, 1)
    min_val = np.min(values)
    max_val = np.max(values)

    # Test with various valid beta values
    for beta in range(0, n_candidates - 1, 2):  # Even values only
        result = _coordinate_wise_trimmed_mean(stacked, beta)
        # Trimmed mean must be within [min, max]
        assert min_val - 1e-6 <= result[0] <= max_val + 1e-6, f"beta={beta}, result={result[0]}, bounds=[{min_val}, {max_val}]"


@given(st.integers(min_value=5, max_value=20))
def test_trimmed_mean_increasing_beta_monotonicity(n_candidates):
    """Property: increasing beta should not make result MORE sensitive to outliers."""
    # Create data with outliers at extremes
    rng = np.random.default_rng(42)
    honest_values = rng.normal(0.0, 1.0, size=n_candidates - 2)
    stacked = np.concatenate([[-100.0], honest_values, [100.0]]).reshape(-1, 1)

    # Compute results for increasing beta (even values)
    results = []
    for beta in range(0, n_candidates - 1, 2):
        try:
            result = _coordinate_wise_trimmed_mean(stacked, beta)
            results.append((beta, result[0]))
        except ValueError:
            break  # Stop if beta becomes too large

    # With more trimming, absolute result should not increase (become more extreme)
    if len(results) >= 2:
        for i in range(len(results) - 1):
            beta1, val1 = results[i]
            beta2, val2 = results[i + 1]
            # More trimming (beta2 > beta1) should not make result more extreme
            # (This is a weak property but useful sanity check)
            assert np.isfinite(val1) and np.isfinite(val2)
