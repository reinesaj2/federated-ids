name: ci

on:
  push:
    branches: ["feat/**", "chore/**", "fix/**", "d2-training-setup"]
  pull_request:
    branches: ["d2-training-setup", "main"]
  schedule:
    - cron: "0 7 * * *"
  workflow_dispatch:
    inputs:
      run_comprehensive:
        description: "Run comprehensive testing (includes d2_quick and extended nightly)"
        required: false
        default: "false"
        type: boolean
      alpha_values:
        description: 'Alpha values for testing (comma-separated, e.g., "0.05,0.1,0.5")'
        required: false
        default: "0.1"
        type: string
      client_count:
        description: "Number of clients for manual runs"
        required: false
        default: "5"
        type: string
      round_count:
        description: "Number of rounds for manual runs"
        required: false
        default: "10"
        type: string

permissions:
  contents: read
  actions: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  fast:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Python setup
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-

      - name: Install deps
        run: |
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Define static-check file list
        run: |
          FILES="server.py client.py logging_utils.py privacy_accounting.py"
          echo "FILES=$FILES" >> "$GITHUB_ENV"

      - name: Static analysis (ruff, black, mypy)
        run: |
          ruff --version
          black --version
          mypy --version
          # Auto-format the selected files, then lint and type-check
          black $FILES
          ruff check $FILES
          mypy $FILES

      - name: Lint & unit tests
        env:
          D2_EXTENDED_METRICS: "1"
        run: |
          if command -v flake8 >/dev/null 2>&1; then flake8 ; fi
          pytest -q

      - name: Smoke FL (only on feature branches)
        if: startsWith(github.ref, 'refs/heads/feat/')
        env:
          D2_EXTENDED_METRICS: "1"
          SEED: "42"
        run: |
          # Function to wait for port
          wait_for_port() {
            local port=$1
            for i in {1..20}; do
              nc -z 127.0.0.1 "$port" 2>/dev/null && return 0
              sleep 0.5
            done
            return 1
          }
          
          # Run IID experiment
          mkdir -p runs/smoke_feat_iid
          LOGDIR=runs/smoke_feat_iid
          PORT=8090
          
          # Start server
          python server.py --rounds 3 --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
          SERVER_PID=$!
          
          # Wait for server
          if ! wait_for_port $PORT; then
            echo "Server failed to start"
            kill $SERVER_PID 2>/dev/null || true
            exit 1
          fi
          
          # Start clients
          python client.py --server_address 127.0.0.1:$PORT --client_id 0 --num_clients 2 --dataset synthetic --samples 1000 --features 20 --partition_strategy iid --alpha 0.1 --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_0.log" 2>&1 &
          C1=$!
          python client.py --server_address 127.0.0.1:$PORT --client_id 1 --num_clients 2 --dataset synthetic --samples 1000 --features 20 --partition_strategy iid --alpha 0.1 --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_1.log" 2>&1 &
          C2=$!
          
          # Wait for completion
          TIMEOUT=60
          for i in $(seq 1 $TIMEOUT); do
            if ! kill -0 $C1 2>/dev/null && ! kill -0 $C2 2>/dev/null; then
              break
            fi
            sleep 1
          done
          
          # Clean up
          sleep 2
          kill $SERVER_PID 2>/dev/null || true
          
          # Run Dirichlet experiment
          mkdir -p runs/smoke_feat_dirichlet
          LOGDIR=runs/smoke_feat_dirichlet
          PORT=8091
          
          # Start server
          python server.py --rounds 3 --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
          SERVER_PID=$!
          
          # Wait for server
          if ! wait_for_port $PORT; then
            echo "Server failed to start"
            kill $SERVER_PID 2>/dev/null || true
            exit 1
          fi
          
          # Start clients
          python client.py --server_address 127.0.0.1:$PORT --client_id 0 --num_clients 2 --dataset synthetic --samples 1000 --features 20 --partition_strategy dirichlet --alpha 0.1 --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_0.log" 2>&1 &
          C1=$!
          python client.py --server_address 127.0.0.1:$PORT --client_id 1 --num_clients 2 --dataset synthetic --samples 1000 --features 20 --partition_strategy dirichlet --alpha 0.1 --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_1.log" 2>&1 &
          C2=$!
          
          # Wait for completion
          for i in $(seq 1 $TIMEOUT); do
            if ! kill -0 $C1 2>/dev/null && ! kill -0 $C2 2>/dev/null; then
              break
            fi
            sleep 1
          done
          
          # Clean up
          sleep 2
          kill $SERVER_PID 2>/dev/null || true

      - name: Upload smoke artifacts
        if: startsWith(github.ref, 'refs/heads/feat/')
        uses: actions/upload-artifact@v4
        with:
          name: smoke-artifacts-${{ github.sha }}
          path: |
            runs/**/metrics.csv
            runs/**/client_*_metrics.csv
            runs/**/client_metrics_plot.png
            runs/**/server_metrics_plot.png

  d2_quick:
    if: github.ref == 'refs/heads/d2-training-setup' || (github.event_name == 'pull_request' && github.base_ref == 'd2-training-setup') || (github.event_name == 'workflow_dispatch' && github.event.inputs.run_comprehensive == 'true')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-
      - run: |
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Benign quick
        env:
          D2_EXTENDED_METRICS: "1"
          SEED: "42"
        run: |
          mkdir -p runs/d2_quick_benign
          LOGDIR=runs/d2_quick_benign
          PORT=8092
          CLIENTS=5
          ROUNDS=10
          
          # Start server
          python server.py --rounds $ROUNDS --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
          SERVER_PID=$!
          
          # Wait for server
          for i in {1..20}; do
            nc -z 127.0.0.1 $PORT 2>/dev/null && break
            sleep 0.5
          done
          
          # Start clients
          for CLIENT_ID in $(seq 0 $((CLIENTS-1))); do
            python client.py --server_address 127.0.0.1:$PORT --client_id $CLIENT_ID --num_clients $CLIENTS --dataset synthetic --samples 1000 --features 20 --partition_strategy dirichlet --alpha 0.1 --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_${CLIENT_ID}.log" 2>&1 &
          done
          
          # Wait for completion
          wait
          sleep 2
          kill $SERVER_PID 2>/dev/null || true
          
      - name: Adversarial quick
        env:
          D2_EXTENDED_METRICS: "1"
          SEED: "42"
        run: |
          mkdir -p runs/d2_quick_adv
          LOGDIR=runs/d2_quick_adv
          PORT=8093
          CLIENTS=5
          ROUNDS=10
          
          # Start server
          python server.py --rounds $ROUNDS --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
          SERVER_PID=$!
          
          # Wait for server
          for i in {1..20}; do
            nc -z 127.0.0.1 $PORT 2>/dev/null && break
            sleep 0.5
          done
          
          # Start clients
          for CLIENT_ID in $(seq 0 $((CLIENTS-1))); do
            python client.py --server_address 127.0.0.1:$PORT --client_id $CLIENT_ID --num_clients $CLIENTS --dataset synthetic --samples 1000 --features 20 --partition_strategy dirichlet --alpha 0.1 --adversary_mode label_flip --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_${CLIENT_ID}.log" 2>&1 &
          done
          
          # Wait for completion
          wait
          sleep 2
          kill $SERVER_PID 2>/dev/null || true
          
      - name: Validate metrics
        run: |
          # Check that metrics files were created
          for dir in runs/*/; do
            if [ -f "$dir/metrics.csv" ]; then
              echo "✓ Found metrics.csv in $dir"
            else
              echo "✗ Missing metrics.csv in $dir"
              exit 1
            fi
          done

      - uses: actions/upload-artifact@v4
        with:
          name: d2-quick-artifacts-${{ github.sha }}
          path: runs/**

  nightly_full:
    runs-on: ubuntu-latest
    timeout-minutes: 240 # 4 hours
    strategy:
      fail-fast: false
      matrix:
        alpha: [0.05, 0.1, 0.5]
        scenario: ["benign", "adversarial"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-
      - name: Install dependencies with retry
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 10
          max_attempts: 3
          retry_on: error
          command: |
            pip install -r requirements.txt
            if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Prepare real dataset samples
        run: python scripts/setup_real_datasets.py

      - name: Full sweep (real-data 5c×20r) - ${{ matrix.scenario }}
        uses: nick-fields/retry@v3
        with:
          timeout_minutes: 200
          max_attempts: 2
          retry_on: error
          command: |
            export D2_EXTENDED_METRICS="1"
            export SEED="42"
            CLIENTS=5
            ROUNDS=20
            ALPHA="${{ matrix.alpha }}"

            DATASET="unsw"
            DATA_PATH="data/unsw/unsw_nb15_sample.csv"
            ADV_MODE=""
            if [ "${{ matrix.scenario }}" = "benign" ]; then
              PRESET="d2_full_${ALPHA}_benign"
            else
              PRESET="d2_full_${ALPHA}_adv"
              DATASET="cic"
              DATA_PATH="data/cic/cic_ids2017_sample.csv"
              ADV_MODE="--adversary_mode label_flip"
            fi

            mkdir -p "runs/$PRESET"
            LOGDIR="runs/$PRESET"
            PORT=$((8100 + RANDOM % 1000))

            echo "$DATASET" >"$LOGDIR/dataset.txt"
            echo "$DATA_PATH" >"$LOGDIR/dataset_path.txt"
            echo "Running nightly_full scenario=${{ matrix.scenario }} alpha=$ALPHA dataset=$DATASET"

            # Start server
            python server.py --rounds $ROUNDS --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
            SERVER_PID=$!
            
            # Wait for server
            for i in {1..20}; do
              nc -z 127.0.0.1 $PORT 2>/dev/null && break
              sleep 0.5
            done
            
            # Start all clients
            CLIENT_PIDS=()
            for CLIENT_ID in $(seq 0 $((CLIENTS-1))); do
              python client.py --server_address 127.0.0.1:$PORT --client_id $CLIENT_ID --num_clients $CLIENTS \
                --dataset "$DATASET" --data_path "$DATA_PATH" --partition_strategy dirichlet --alpha $ALPHA \
                --logdir "$LOGDIR" --leakage_safe --seed 42 $ADV_MODE >"$LOGDIR/client_${CLIENT_ID}.log" 2>&1 &
              CLIENT_PIDS+=($!)
            done
            
            # Wait for all clients with timeout
            TIMEOUT=3600  # 60 minutes
            START_TIME=$SECONDS
            while true; do
              ALL_DONE=true
              for PID in "${CLIENT_PIDS[@]}"; do
                if kill -0 $PID 2>/dev/null; then
                  ALL_DONE=false
                  break
                fi
              done
              
              if $ALL_DONE; then
                echo "All clients completed"
                break
              fi
              
              if [ $((SECONDS - START_TIME)) -gt $TIMEOUT ]; then
                echo "Timeout reached, killing processes"
                for PID in "${CLIENT_PIDS[@]}"; do
                  kill $PID 2>/dev/null || true
                done
                kill $SERVER_PID 2>/dev/null || true
                exit 1
              fi
              
              sleep 5
            done
            
            # Clean up server
            sleep 5
            kill $SERVER_PID 2>/dev/null || true
            
            # Verify metrics file exists
            if [ ! -f "$LOGDIR/metrics.csv" ]; then
              echo "Missing metrics.csv in $LOGDIR"
              exit 1
            fi

      - name: Validate results
        run: |
          # Basic validation of results
          PRESET="d2_full_${{ matrix.alpha }}_${{ matrix.scenario }}"
          if [ "${{ matrix.scenario }}" = "adversarial" ]; then
            PRESET="d2_full_${{ matrix.alpha }}_adv"
          else
            PRESET="d2_full_${{ matrix.alpha }}_benign"
          fi
          LOGDIR="runs/$PRESET"
          
          if [ -f "$LOGDIR/metrics.csv" ]; then
            echo "✓ Found metrics.csv"
            # Check that we have expected number of rounds
            LINES=$(wc -l < "$LOGDIR/metrics.csv")
            echo "  Metrics has $LINES lines"
          else
            echo "✗ Missing metrics.csv"
            exit 1
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: d2-full-${{ matrix.alpha }}-${{ matrix.scenario }}-${{ github.sha }}
          path: runs/**
          retention-days: 30

  nightly_notify:
    needs: nightly_full
    runs-on: ubuntu-latest
    if: always() && needs.nightly_full.result == 'failure'
    steps:
      - name: Log nightly failure (issues disabled)
        run: |
          echo "🚨 Nightly CI Pipeline Failed"
          echo "Workflow Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "Branch: ${{ github.ref }}"
          echo "Commit: ${{ github.sha }}"
          echo "Failed at: $(date)"
          echo "Check the workflow run for details"

  manual_testing:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        scenario: ["benign", "adversarial"]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Parse alpha values and run tests
        env:
          D2_EXTENDED_METRICS: "1"
          SEED: "42"
        run: |
          IFS=',' read -ra ALPHAS <<< "${{ github.event.inputs.alpha_values }}"
          CLIENTS=${{ github.event.inputs.client_count }}
          ROUNDS=${{ github.event.inputs.round_count }}
          
          for alpha in "${ALPHAS[@]}"; do
            alpha=$(echo "$alpha" | xargs)  # trim whitespace
            
            if [ "${{ matrix.scenario }}" = "benign" ]; then
              PRESET="manual_${alpha}_benign"
              ADV_MODE=""
            else
              PRESET="manual_${alpha}_adv"
              ADV_MODE="--adversary_mode label_flip"
            fi
            
            mkdir -p "runs/$PRESET"
            LOGDIR="runs/$PRESET"
            PORT=$((9000 + RANDOM % 1000))
            
            echo "Running experiment: $PRESET (port=$PORT)"
            
            # Start server
            python server.py --rounds $ROUNDS --aggregation fedavg --server_address 127.0.0.1:$PORT --logdir "$LOGDIR" >"$LOGDIR/server.log" 2>&1 &
            SERVER_PID=$!
            
            # Wait for server
            for i in {1..20}; do
              nc -z 127.0.0.1 $PORT 2>/dev/null && break
              sleep 0.5
            done
            
            # Start all clients
            CLIENT_PIDS=()
            for CLIENT_ID in $(seq 0 $((CLIENTS-1))); do
              python client.py --server_address 127.0.0.1:$PORT --client_id $CLIENT_ID --num_clients $CLIENTS \
                --dataset synthetic --samples 1000 --features 20 --partition_strategy dirichlet --alpha "$alpha" \
                $ADV_MODE --logdir "$LOGDIR" --leakage_safe --seed 42 >"$LOGDIR/client_${CLIENT_ID}.log" 2>&1 &
              CLIENT_PIDS+=($!)
            done
            
            # Wait for all clients
            for PID in "${CLIENT_PIDS[@]}"; do
              wait $PID
            done
            
            # Clean up server
            sleep 2
            kill $SERVER_PID 2>/dev/null || true
            
            # Verify metrics
            if [ ! -f "$LOGDIR/metrics.csv" ]; then
              echo "Warning: Missing metrics.csv in $LOGDIR"
            else
              echo "✓ Completed $PRESET"
            fi
          done

      - name: Validate results
        run: |
          # Check that all expected directories have metrics
          FOUND=0
          for dir in runs/*/; do
            if [ -f "$dir/metrics.csv" ]; then
              echo "✓ Found metrics in $(basename $dir)"
              FOUND=$((FOUND + 1))
            fi
          done
          echo "Total experiments with metrics: $FOUND"
          if [ $FOUND -eq 0 ]; then
            echo "Error: No experiments produced metrics"
            exit 1
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: manual-test-${{ matrix.scenario }}-${{ github.sha }}
          path: runs/**
          retention-days: 7

  release_on_tag:
    if: startsWith(github.ref, 'refs/tags/D2-')
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Create GitHub Release
        run: |
          gh release create "${GITHUB_REF_NAME}" --notes-from-tag --title "Deliverable 2 – ${GITHUB_REF_NAME}"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      - name: Optionally upload run artifacts if present
        run: |
          set -e
          FILES=$(ls runs/**/client_metrics_plot.png runs/**/server_metrics_plot.png runs/**/metrics.csv 2>/dev/null || true)
          if [ -n "$FILES" ]; then
            gh release upload "${GITHUB_REF_NAME}" $FILES
          else
            echo "No run artifacts found; skipping upload."
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
