name: Comparative Analysis Nightly

on:
  push:
    branches: ["exp/issue-44-comprehensive-experiments", "milestone/m1-experiments-core"]
  schedule:
    - cron: "0 3 * * 0" # 3 AM UTC every Sunday
  workflow_dispatch:
    inputs:
      dimensions:
        description: "Dimensions to run (comma-separated: aggregation,heterogeneity,attack,privacy,personalization,all)"
        required: false
        default: "all"
        type: string
      num_clients:
        description: "Number of clients"
        required: false
        default: "6"
        type: string
      num_rounds:
        description: "Number of rounds"
        required: false
        default: "20"
        type: string
      run_cic:
        description: "Run CIC-IDS2017 experiments (doubles execution time)"
        required: false
        default: "true"
        type: boolean

permissions:
  contents: write
  actions: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  comparative_analysis:
    runs-on: ubuntu-latest
    timeout-minutes: 900 # 15 hours for expanded grids (Issue #44)
    strategy:
      fail-fast: false
      max-parallel: 1 # Sequential execution for expanded grids
      matrix:
        dimension:
          [aggregation, heterogeneity, heterogeneity_fedprox, attack, privacy, personalization]
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          if [ -f requirements-dev.txt ]; then pip install -r requirements-dev.txt; fi

      - name: Validate experiment matrix
        run: |
          echo "Pre-flight check: Validating experiment matrix feasibility"
          python scripts/validate_experiment_matrix.py > matrix_validation.log
          cat matrix_validation.log
          echo "Matrix validation complete. Proceeding with experiments."

      - name: Prepare real dataset samples
        run: python scripts/setup_real_datasets.py

      - name: Run comparative analysis (UNSW dataset)
        env:
          D2_EXTENDED_METRICS: "1"
        run: |
          CLIENTS=${{ github.event.inputs.num_clients || '6' }}
          ROUNDS=${{ github.event.inputs.num_rounds || '20' }}

          echo "Starting comparative analysis for dimension: ${{ matrix.dimension }} (UNSW)"
          echo "System resources:"
          echo "  Memory: $(free -h | grep '^Mem:' | awk '{print $2}')"
          echo "  CPU cores: $(nproc)"
          echo "  Disk space: $(df -h . | tail -1 | awk '{print $4}')"
          
          # Run UNSW experiments
          python scripts/comparative_analysis.py \
            --dimension ${{ matrix.dimension }} \
            --dataset unsw \
            --output_dir results/comparative_analysis/unsw

      - name: Run comparative analysis (CIC dataset)
        if: github.event.inputs.run_cic != 'false'
        env:
          D2_EXTENDED_METRICS: "1"
        run: |
          echo "Starting comparative analysis for dimension: ${{ matrix.dimension }} (CIC-IDS2017)"
          echo "Using expanded grids per Issue #44 acceptance criteria"
          
          # Run CIC experiments with expanded grids
          python scripts/comparative_analysis.py \
            --dimension ${{ matrix.dimension }} \
            --dataset cic \
            --output_dir results/comparative_analysis/cic

      - name: Validate gradient norms
        continue-on-error: true
        run: |
          echo "Validating gradient norms for dimension: ${{ matrix.dimension }}"
          python scripts/validate_grad_norms.py --runs_dir runs --fail_on_missing || echo "WARNING: Gradient norm validation failed (non-blocking)"

      - name: Generate thesis plots
        run: |
          echo "Generating thesis plots for dimension: ${{ matrix.dimension }}"
          
          # Check if we have experiment data
          if [ ! -d "runs" ] || [ -z "$(ls -A runs/comp_* 2>/dev/null)" ]; then
            echo "ERROR: No experiment data found in runs/ directory"
            echo "Available directories:"
            ls -la runs/ || echo "runs/ directory does not exist"
            exit 1
          fi
          
          # Generate plots with error handling
          python scripts/generate_thesis_plots.py \
            --dimension ${{ matrix.dimension }} \
            --runs_dir runs \
            --output_dir results/thesis_plots/${{ matrix.dimension }}
          
          # Verify plots were generated
          if [ -d "results/thesis_plots/${{ matrix.dimension }}" ]; then
            PLOT_COUNT=$(find results/thesis_plots/${{ matrix.dimension }} -name "*.png" -o -name "*.pdf" | wc -l)
            echo "Generated $PLOT_COUNT plots for ${{ matrix.dimension }}"
          else
            echo "ERROR: No plots generated for ${{ matrix.dimension }}"
            exit 1
          fi

      - name: Validate results
        run: |
          echo "Validating experiment results..."
          FOUND=0
          FAILED=0
          TOTAL=0
          
          for dir in runs/comp_*/; do
            TOTAL=$((TOTAL + 1))
            if [ -f "$dir/metrics.csv" ]; then
              echo "Found metrics in $(basename $dir)"
              FOUND=$((FOUND + 1))
            else
              echo "Missing metrics in $(basename $dir)"
              FAILED=$((FAILED + 1))
            fi
          done
          
          echo "VALIDATION SUMMARY:"
          echo "  Total experiments: $TOTAL"
          echo "  Successful: $FOUND"
          echo "  Failed: $FAILED"
          echo "  Success rate: $((FOUND * 100 / TOTAL))%"
          
          # Require at least 95% success rate (allow max 3 transient failures out of 54 viable experiments)
          THRESHOLD=$((TOTAL * 95 / 100))
          if [ $FOUND -eq 0 ]; then
            echo "ERROR: No experiments produced metrics"
            exit 1
          elif [ $FOUND -lt $THRESHOLD ]; then
            echo "ERROR: Success rate $((FOUND * 100 / TOTAL))% below required 95% ($FOUND/$TOTAL experiments)"
            echo "This indicates systematic issues. Please review:"
            echo "  - Byzantine constraint violations"
            echo "  - Resource exhaustion"
            echo "  - Port conflicts"
            exit 1
          else
            echo "SUCCESS: Adequate experiment completion rate ($((FOUND * 100 / TOTAL))%)"
          fi

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: comparative-analysis-${{ matrix.dimension }}-${{ github.sha }}
          path: |
            runs/comp_**/metrics.csv
            runs/comp_**/client_*_metrics.csv
            runs/comp_**/config.json
            runs/comp_**/*.log
            results/thesis_plots/${{ matrix.dimension }}/**/*.png
            results/thesis_plots/${{ matrix.dimension }}/**/*.pdf
          retention-days: 90

  consolidated_summary:
    needs: comparative_analysis
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install pandas matplotlib seaborn numpy scipy

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: comparative-artifacts

      - name: Generate consolidated summary
        run: |
          mkdir -p thesis-summary

          # Collect all thesis plots into one directory
          find comparative-artifacts -name "*.png" -o -name "*.pdf" | while read file; do
            cp "$file" thesis-summary/
          done

          # Create markdown index
          cat > thesis-summary/README.md << 'EOF'
          # Comparative Analysis Thesis Plots

          Auto-generated on $(date)

          ## Available Plots

          EOF

          for dim in aggregation heterogeneity attack privacy personalization; do
            echo "### $dim" >> thesis-summary/README.md
            find thesis-summary -name "*${dim}*.png" | while read plot; do
              echo "- ![$(basename $plot)]($(basename $plot))" >> thesis-summary/README.md
            done
            echo "" >> thesis-summary/README.md
          done

      - name: Upload consolidated results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: thesis-plots-summary-${{ github.sha }}
          path: thesis-summary/**
          retention-days: 90

  commit_thesis_plots:
    needs: [consolidated_summary]
    runs-on: ubuntu-latest
    if: always() && needs.consolidated_summary.result == 'success'
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download consolidated results
        uses: actions/download-artifact@v4
        with:
          name: thesis-plots-summary-${{ github.sha }}
          path: thesis-summary

      - name: Commit plots to repository
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"

          mkdir -p plots/thesis

          # Copy thesis plots
          if [ -d "thesis-summary" ]; then
            python scripts/commit_plots.py \
              --source_dir thesis-summary \
              --experiment_type thesis-comparative \
              --plots_dir plots/thesis
          fi

      - name: Push plots to repository
        run: |
          # Check if there are unpushed commits
          if git log origin/main..HEAD --oneline | grep -q .; then
            git push origin main
          else
            echo "No commits to push"
          fi

  notify_failure:
    needs: comparative_analysis
    runs-on: ubuntu-latest
    if: always() && needs.comparative_analysis.result == 'failure'
    steps:
      - name: Log comparative analysis failure
        run: |
          echo "ðŸš¨ Comparative Analysis Nightly Failed"
          echo "Workflow Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo "Branch: ${{ github.ref }}"
          echo "Commit: ${{ github.sha }}"
          echo "Failed at: $(date)"
